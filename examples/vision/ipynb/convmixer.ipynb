{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install -U -q tensorflow-addons"
      ],
      "metadata": {
        "id": "AHMwAItRzYLU",
        "outputId": "f7cf0db7-4668-40ec-869b-e993e95fddd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/591.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m583.7/591.0 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uME3dCbWxed0"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W-jSeUEDxed5",
        "outputId": "b81416e1-aa36-4ce1-d4e8-c4c0ab2da824",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N6cx2lbHxeew"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 32\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GL6njKb2zo90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Bmx-0GxSzqNA",
        "outputId": "4a93b438-4b41-4d25-fe4d-90c30d64d54e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pathlib\n",
        "\n",
        "# Define the paths to the training and testing data folders\n",
        "train_data_path = \"/content/drive/MyDrive/PreprocessSeg\"\n",
        "test_data_path = \"/content/drive/MyDrive/PreprocessSeg\"\n",
        "\n",
        "# Use TensorFlow's image data generator to load the images and labels from the folders\n",
        "train_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "test_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data = train_data_generator.flow_from_directory(directory=train_data_path,\n",
        "                                                      target_size=(128, 128),\n",
        "                                                      batch_size=32,\n",
        "                                                      class_mode='categorical',\n",
        "                                                      shuffle=True)\n",
        "\n",
        "test_data = test_data_generator.flow_from_directory(directory=test_data_path,\n",
        "                                                    target_size=(128,128),\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    shuffle=False)\n",
        "\n",
        "# Print the shapes of the data and labels\n",
        "print(\"Training data shape:\", train_data.image_shape)\n",
        "print(\"Training labels shape:\", train_data.classes.shape)\n",
        "print(\"Testing data shape:\", test_data.image_shape)\n",
        "print(\"Testing labels shape:\", test_data.classes.shape)\n",
        "\n",
        "# Assign the data and labels to variables x_train, y_train, x_test, and y_test\n",
        "x_train, y_train = train_data.next()\n",
        "x_test, y_test = test_data.next()\n"
      ],
      "metadata": {
        "id": "-GhlxH4Hzk-T",
        "outputId": "635c5404-f8c0-4075-a5e0-3be40ea03bf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1921 images belonging to 4 classes.\n",
            "Found 1921 images belonging to 4 classes.\n",
            "Training data shape: (128, 128, 3)\n",
            "Training labels shape: (1921,)\n",
            "Testing data shape: (128, 128, 3)\n",
            "Testing labels shape: (1921,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ReP2ciSckvAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0SQdtTY8xegV",
        "outputId": "2dc76115-db10-4d70-8fa4-79b60a4815d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data samples: 29\n",
            "Validation data samples: 3\n",
            "Test data samples: 32\n"
          ]
        }
      ],
      "source": [
        "#(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "val_split = 0.1\n",
        "\n",
        "val_indices = int(len(x_train) * val_split)\n",
        "new_x_train, new_y_train = x_train[val_indices:], y_train[val_indices:]\n",
        "x_val, y_val = x_train[:val_indices], y_train[:val_indices]\n",
        "\n",
        "print(f\"Training data samples: {len(new_x_train)}\")\n",
        "print(f\"Validation data samples: {len(x_val)}\")\n",
        "print(f\"Test data samples: {len(x_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Assume y_train and y_test have a shape of [?, 4]\n",
        "# Convert them to integer labels\n",
        "y_train_int = np.argmax(y_train, axis=1)\n",
        "y_test_int = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Now you can convert them to one-hot encoded vectors with num_classes=4\n",
        "y_train = tf.keras.utils.to_categorical(y_train_int, num_classes=4)\n",
        "y_test = tf.keras.utils.to_categorical(y_test_int, num_classes=4)\n",
        "\n",
        "y_train = y_train.squeeze()\n",
        "y_test = y_test.squeeze()\n"
      ],
      "metadata": {
        "id": "W6Br9_MSkIOy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ac6nBSgxegg"
      },
      "source": [
        "## Prepare `tf.data.Dataset` objects\n",
        "\n",
        "Our data augmentation pipeline is different from what the authors used for the CIFAR-10\n",
        "dataset, which is fine for the purpose of the example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcoWGrd5xegj"
      },
      "outputs": [],
      "source": [
        "image_size = 176\n",
        "auto = tf.data.AUTOTUNE\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [layers.RandomCrop(image_size, image_size), layers.RandomFlip(\"horizontal\"),],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "\n",
        "\n",
        "def make_datasets(images, labels, is_train=False):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    if is_train:\n",
        "        dataset = dataset.shuffle(batch_size * 10)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    if is_train:\n",
        "        dataset = dataset.map(\n",
        "            lambda x, y: (data_augmentation(x), y), num_parallel_calls=auto\n",
        "        )\n",
        "    return dataset.prefetch(auto)\n",
        "\n",
        "\n",
        "train_dataset = make_datasets(new_x_train, new_y_train, is_train=True)\n",
        "val_dataset = make_datasets(x_val, y_val)\n",
        "test_dataset = make_datasets(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdwVUtpXxegn"
      },
      "source": [
        "## ConvMixer utilities\n",
        "\n",
        "The following figure (taken from the original paper) depicts the ConvMixer model:\n",
        "\n",
        "![](https://i.imgur.com/yF8actg.png)\n",
        "\n",
        "ConvMixer is very similar to the MLP-Mixer, model with the following key\n",
        "differences:\n",
        "\n",
        "* Instead of using fully-connected layers, it uses standard convolution layers.\n",
        "* Instead of LayerNorm (which is typical for ViTs and MLP-Mixers), it uses BatchNorm.\n",
        "\n",
        "Two types of convolution layers are used in ConvMixer. **(1)**: Depthwise convolutions,\n",
        "for mixing spatial locations of the images, **(2)**: Pointwise convolutions (which follow\n",
        "the depthwise convolutions), for mixing channel-wise information across the patches.\n",
        "Another keypoint is the use of *larger kernel sizes* to allow a larger receptive field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YPE2IxmbxehD"
      },
      "outputs": [],
      "source": [
        "\n",
        "def activation_block(x):\n",
        "    x = layers.Activation(\"gelu\")(x)\n",
        "    return layers.BatchNormalization()(x)\n",
        "\n",
        "\n",
        "def conv_stem(x, filters: int, patch_size: int):\n",
        "    x = layers.Conv2D(filters, kernel_size=patch_size, strides=patch_size)(x)\n",
        "    return activation_block(x)\n",
        "\n",
        "\n",
        "def conv_mixer_block(x, filters: int, kernel_size: int):\n",
        "    # Depthwise convolution.\n",
        "    x0 = x\n",
        "    x = layers.DepthwiseConv2D(kernel_size=kernel_size, padding=\"same\")(x)\n",
        "    x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "\n",
        "    # Pointwise convolution.\n",
        "    x = layers.Conv2D(filters, kernel_size=1)(x)\n",
        "    x = activation_block(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_conv_mixer_256_8(\n",
        "    image_size=128, filters=256, depth=8, kernel_size=5, patch_size=2, num_classes=4\n",
        "):\n",
        "    \"\"\"ConvMixer-256/8: https://openreview.net/pdf?id=TVHS5Y4dNvM.\n",
        "    The hyperparameter values are taken from the paper.\n",
        "    \"\"\"\n",
        "    inputs = keras.Input((image_size, image_size, 3))\n",
        "    x = layers.Rescaling(scale=1.0 / 255)(inputs)\n",
        "\n",
        "    # Extract patch embeddings.\n",
        "    x = conv_stem(x, filters, patch_size)\n",
        "\n",
        "    # ConvMixer blocks.\n",
        "    for _ in range(depth):\n",
        "        x = conv_mixer_block(x, filters, kernel_size)\n",
        "\n",
        "    # Classification block.\n",
        "    x = layers.GlobalAvgPool2D()(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKISV-yrxehS"
      },
      "source": [
        "## Model training and evaluation utility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "gq1Box8BxehT"
      },
      "outputs": [],
      "source": [
        "def run_experiment(model):\n",
        "    optimizer = tfa.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=\"categorical_crossentropy\", # use categorical crossentropy loss\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        new_x_train,  # use new_x_train instead of x_train\n",
        "        new_y_train,  # use new_y_train instead of y_train\n",
        "        epochs=num_epochs,\n",
        "        validation_split=0.2,\n",
        "        callbacks=[checkpoint_callback],\n",
        "    )\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    _, accuracy = model.evaluate(test_data)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history, model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fu3Lk-zWxehW"
      },
      "source": [
        "## Train and evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "zY9GRd_Qxehl",
        "outputId": "00924d2e-e725-4fd2-d31d-2118a7995dda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 47s 47s/step - loss: 1.3963 - accuracy: 0.2174 - val_loss: 1.3769 - val_accuracy: 0.3333\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 33s 33s/step - loss: 1.3130 - accuracy: 0.4783 - val_loss: 1.3682 - val_accuracy: 0.3333\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 33s 33s/step - loss: 1.1810 - accuracy: 0.6087 - val_loss: 1.3597 - val_accuracy: 0.3333\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 34s 34s/step - loss: 1.0577 - accuracy: 0.6087 - val_loss: 1.3510 - val_accuracy: 0.3333\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.9434 - accuracy: 0.6957 - val_loss: 1.3424 - val_accuracy: 0.3333\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 31s 31s/step - loss: 0.8392 - accuracy: 0.7391 - val_loss: 1.3340 - val_accuracy: 0.3333\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 34s 34s/step - loss: 0.7231 - accuracy: 0.7826 - val_loss: 1.3265 - val_accuracy: 0.3333\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 35s 35s/step - loss: 0.6084 - accuracy: 0.8696 - val_loss: 1.3214 - val_accuracy: 0.3333\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 36s 36s/step - loss: 0.5563 - accuracy: 0.9130 - val_loss: 1.3176 - val_accuracy: 0.3333\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 35s 35s/step - loss: 0.5475 - accuracy: 0.8261 - val_loss: 1.3181 - val_accuracy: 0.3333\n",
            "61/61 [==============================] - 731s 12s/step - loss: 1.3781 - accuracy: 0.3384\n",
            "Test accuracy: 33.84%\n"
          ]
        }
      ],
      "source": [
        "conv_mixer_model = get_conv_mixer_256_8()\n",
        "history, conv_mixer_model = run_experiment(conv_mixer_model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "convmixer",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}